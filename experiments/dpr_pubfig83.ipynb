{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks with DPR on PubFig83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/project-1/experiments\n",
      "/home/jupyter/project-1\n",
      "0.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "os.chdir('/home/jupyter/project-1')\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "from relighters.DPR.model.defineHourglass_512_gray_skip import HourglassNet\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from kornia import color\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from os import walk\n",
    "import os\n",
    "from classifiers.FaceNet.Facenet import FaceNet\n",
    "from classifiers.FaceNet.Facenet import crop_images_batch\n",
    "from relighters.DPR.preparation import load_np_img, np_rgb_to_torch_luv\n",
    "from relighters.DPR.face_utils import plot_face_attack, get_sh\n",
    "from relighters.DPR.spherical_harmonics import get_random_spherical_harmonics\n",
    "\n",
    "print(torchvision.__version__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/PubFig/embedding'\n",
    "embeddings_old = np.load('/home/jupyter/project-1/data/pubfig83/pubfig83_embedding.npz')['X_train']\n",
    "embeddings = []\n",
    "for em in embeddings_old:\n",
    "    embeddings.append(em[0])\n",
    "labels = np.load('/home/jupyter/project-1/data/pubfig83/pubfig83_embedding.npz')['y_train']\n",
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))\n",
    "print(len(labels))\n",
    "embeddings = torch.nn.functional.normalize(torch.Tensor(embeddings), p=2, dim=1, eps=1e-12, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = FaceNet(num_classes=83, load_model=False)\n",
    "loss_history = classifier.train(torch.Tensor(embeddings), torch.Tensor(labels), num_steps=100, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "modelFolder = 'relighters/DPR/trained_model/'\n",
    "\n",
    "my_network = HourglassNet()\n",
    "my_network.load_state_dict(torch.load(os.path.join(modelFolder, 'trained_model_03.t7')))\n",
    "my_network.train(False)\n",
    "relighting = my_network\n",
    "learning_rate = 0.015\n",
    "max_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cropped images and labels for data folder\n",
    "crops = np.load('/home/jupyter/project-1/data/pubfig83/pubfig83_crop_test.npz')['data']\n",
    "labels = np.load('/home/jupyter/project-1/data/pubfig83/pubfig83_crop_test.npz')['labels']\n",
    "\n",
    "total, ad, f = 0, 0, 0\n",
    "reg = 0.5\n",
    "\n",
    "# loop over test data\n",
    "for id, image in enumerate(crops):    \n",
    "    loss_history = []\n",
    "    img_np = image\n",
    "    \n",
    "    # get prediction on input image\n",
    "    img_np_mod = (torch.Tensor(image).permute(1, 2, 0) - 0.5) / 0.50196078\n",
    "    output = classifier.predict(img_np_mod.permute(2, 0, 1).unsqueeze(0))\n",
    "    ogprob.append(output)\n",
    "    orig_prob, orig_label = torch.max(output, dim=1)\n",
    "    \n",
    "    # l-space transformations\n",
    "    img_luv = np_rgb_to_torch_luv(img_np)\n",
    "    input_l = img_luv[0,:, :]\n",
    "    input_l = (input_l/100.0) # DPR expects values between 0 and 1\n",
    "    input_l = input_l[None,None, ...] \n",
    "    input_uv = img_luv[1:,:,: ]\n",
    "    input_l = input_l.float()\n",
    "    \n",
    "    # initialize shade params\n",
    "    estimated_sh = get_sh(input_l).detach()\n",
    "    sh = get_random_spherical_harmonics()\n",
    "    sh = Variable(sh, requires_grad=True)\n",
    "    \n",
    "    # optimization loop to find optimal shade parameters\n",
    "    with torch.enable_grad():\n",
    "        for i in range(max_steps):\n",
    "            # relight the current image\n",
    "            current_sh = sh.clone()\n",
    "            current_sh = Variable(current_sh, requires_grad=True)\n",
    "            out_l, out_sh  = relighting(input_l, current_sh, 0)\n",
    "            out_l_perm = out_l[0]\n",
    "            out_l_scaled = (out_l_perm*100.0)\n",
    "            output_luv = torch.cat([out_l_scaled.double(), input_uv.double()], dim=0)\n",
    "            output_rgb = color.luv_to_rgb(output_luv.detach()).requires_grad_(True)\n",
    "            \n",
    "            # normalize, classify and calculate loss\n",
    "            output_rgb_norm = (output_rgb - 0.5) / 0.50196078\n",
    "            probs = classifier.predict(output_rgb_norm.float().unsqueeze(0), log=True)\n",
    "            probability, prediction = torch.max(probs, dim=1)\n",
    "            nll = nn.functional.nll_loss(probs, orig_label)\n",
    "            loss = nll - nll * reg * torch.dist(estimated_sh, current_sh, p=2)\n",
    "            loss_history.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # get gradients and update sh\n",
    "            grad1 = output_rgb.grad\n",
    "            output_luv.backward(gradient=grad1)\n",
    "            grad = current_sh.grad\n",
    "            current_sh = current_sh + learning_rate * grad\n",
    "            sh = current_sh.clone()\n",
    "            output_rgb.grad.zero_()\n",
    "            \n",
    "    # plot results\n",
    "    total += 1\n",
    "    if torch.mean(output_rgb) < 0.1 or torch.mean(output_rgb) > 0.9:\n",
    "        f += 1\n",
    "    else:\n",
    "        if orig_label != prediction:\n",
    "            ad += 1\n",
    "    print(\"total images processed: \", total)\n",
    "    print(\"adversarial examples: \", ad)\n",
    "    print(\"failed relightings: \", f)\n",
    "\n",
    "    plot_face_attack(torch.clamp(torch.Tensor(img_np), 0, 1), torch.clamp(output_rgb, 0, 1), loss_history, sh, out_sh, orig_label, \n",
    "                     orig_prob, prediction, probability)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
